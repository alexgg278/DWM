{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWM (Dynamic Weighted Majority)\n",
    "\n",
    "In this notebook the algorithm DWM for concept drift handleling is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como inizializar para predecir la primera vez?? Inicializaciones son diferentes para las diferentes implementaciones\n",
    "# df.get_dummies automatically (that is not necessary to generate 100 samples to count with all the columns)\n",
    "# Weighted sum?\n",
    "# How to create noise for dataset and to implement p?\n",
    "# Which is the target label in real dataset?\n",
    "# How to evaluate model performance in real Datasets?\n",
    "# Margin of confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwm Implementation\n",
    "\n",
    "\n",
    "* **Concept Drift:** It is the phenomena in which the label of data instances shifts over time, i.e., two similar samples will have different label depending on the time.\n",
    "\n",
    "* **Ensemble Methods:** It is the method in which several learnes are used to train different classifiers to later predict the class label based on a voting or weighted approach.\n",
    "\n",
    "    * *Bagging*\n",
    "    * *Boosting*\n",
    "    * *Stacking*\n",
    "    \n",
    "**<font color=blue>DWM algorithm</font>**\n",
    "\n",
    "* ***Description:***\n",
    "\n",
    "    - The formal algorithm for DWM appears in Figure 1. The algorithm maintains a set of m experts, E, each with a weight, wi for i = 1,...,m. Input to the algorithm is n training examples, each consisting of a feature vector and a class label. The parameters also include the number of classes(c) and β, a multiplicative factor that DWM uses to decrease an expert’s weight when it predicts incorrectly. A typical value for β is 0.5. The parameter θ is a threshold for removing poorly performing experts. If an expert’s weight falls below this threshold, then DWM removes it from the ensemble. Finally, the parameter p determines how often DWM creates and removes experts. We found this parameter useful and necessary for large or noisy problems, which we discuss further inSection 4.2. In the following discussion, we assume p = 1. \n",
    "    \n",
    "    - DWM begins by creating an ensemble containing a single learner with a weight of one (lines 1–3 of Figure 1). Initially, this learner could predict a default class, or it could predict using previous experience, background knowledge, or both. DWM then takes a single example (or perhaps a set ofexamples) from the stream and presents it to the single learner to classify (line 7). If the learner’s prediction is wrong (line 8), then DWM decreases the learner’s weight by multiplying it by β (line 9). Since there is one expert in the ensemble, its prediction is DWM’s global prediction (lines 12 and 24). \n",
    "    \n",
    "    - If DWM’s global prediction is incorrect (line 16), then it creates a new learner with a weight of one (lines 17–19). DWM then trains the experts in the ensemble on the new example (line 23). After training, DWM outputs its global prediction (line 24). When there are multiple learners, DWM obtains a classification from each member of the ensemble (lines 6 and 7). If one’s prediction is incorrect, then DWM decreases its weight (lines 8 and 9). Regardless of the correctness of the prediction, DWM uses each learner’s prediction and its weight to compute a weighted sum for each class (line 10). The class with the most weight is set as the global prediction (line 12). \n",
    "    \n",
    "    - Since DWM always decreases the weights of experts, it normalizes the weights by scaling them uniformly so that, after the transformation, the maximum weight is one (line 14). This prevents newly added experts from dominating predictions. DWM also removes poorly performing experts by removing those with a weight less than the threshold θ (line 15), although it will not remove the last expert in the ensemble. As mentioned previously, if the global prediction is incorrect (line 16), DWM adds a new expert to the ensemble with a weight of one (lines 17–19). Finally, after using the new example to train each learner in the ensemble (lines 22 and 23), DWM outputs the global prediction, which is the weighted vote of the expert predictions (line 24).\n",
    "    \n",
    "    - As mentioned previously, the parameter p lets DWM better cope with many or noisy examples. p defines the period over which DWM will not update learners’ weights (line 8) and will not remove or create experts (line 13). During this period, however, DWM still trains the learners (lines 22 and 23).\n",
    "    \n",
    "    - DWM is a general algorithm for coping with concept drift. One can use any online learning algorithm as the base learner. To date, we have evaluated two such algorithms, naive Bayes and Incremental Tree Inducer, and we describe these versions in the next two sections.\n",
    "\n",
    " \n",
    "* ***Elements:***\n",
    "\n",
    "    - m: Number of experts\n",
    "    - E: Expert\n",
    "    - wj: Expert's weight\n",
    "    - n: Input training samples\n",
    "    - c: number of classes\n",
    "    - β: decreasing weight factor (0 ≤ β < 1)\n",
    "    - θ: Removing learner weight threshold\n",
    "    - p: How often DWM removes or update weights\n",
    "    - Λ,λ ∈ {1,..., c}: global and local predictions\n",
    "\n",
    "\n",
    "* ***Algorithm:***\n",
    "\n",
    "    / 1. m ← 1\n",
    "\n",
    "    / 2. em ← Create-New-Expert()\n",
    "\n",
    "    / 3. wm ← 1\n",
    "\n",
    "    / 4. for i ← 1,...,n // Loop over examples\n",
    "\n",
    "        / 5. ~σ ← 0\n",
    "\n",
    "        / 6. for j ← 1,...,m // Loop over experts\n",
    "\n",
    "            / 7. λ ← Classify(e j,~xi)\n",
    "\n",
    "            / 8. if (λ 6= yi and i mod p = 0)\n",
    "\n",
    "                / 9. wj ← βwj\n",
    "\n",
    "            / 10. σλ ← σλ +wj\n",
    "\n",
    "        / 11. end;\n",
    "\n",
    "        / 12. Λ ← argmaxj σj\n",
    "\n",
    "        / 13. if (i mod p = 0)\n",
    "\n",
    "            / 14. w ← Normalize-Weights(w)\n",
    "\n",
    "            / 15. {e,w} ← Remove-Experts({e,w},θ)\n",
    "\n",
    "            / 16. if (Λ 6= yi)\n",
    "\n",
    "                / 17. m ← m+1\n",
    "\n",
    "                / 18. em ← Create-New-Expert()\n",
    "\n",
    "                / 19. wm ← 1\n",
    "\n",
    "            / 20. end;\n",
    "\n",
    "        / 21. end;\n",
    "\n",
    "        / 22. for j ← 1,...,m\n",
    "\n",
    "            / 23. e j ← Train(e j,~xi, yi)\n",
    "\n",
    "            / 24. output Λ\n",
    "\n",
    "        end;\n",
    "\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_weights(w):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # w: list with learners weights\n",
    "    #\n",
    "    # OUTPUT\n",
    "    # w: updated list with normalized weights. The weights are normalized so the highest weight is 1\n",
    "    ########################################################\n",
    "    maximum = w[0]\n",
    "    for i in range(1,len(w)):\n",
    "        if maximum < w[i]:\n",
    "            maximum = w[i]\n",
    "    for i in range(len(w)):\n",
    "        w[i] = w[i] / maximum\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_experts(E, w, theta, m):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # E: list with learners\n",
    "    # w: list with weights\n",
    "    # theta: weight threshold to eliminate learner\n",
    "    # m: current number of learners\n",
    "    #\n",
    "    # OUTPUT\n",
    "    # list_E: Updated list of learners without model which weight was lower than theta\n",
    "    # list_w: Updated list of weights where the weight corresponding to the eliminated learner is dropped\n",
    "    # m: Updated number of learners\n",
    "    ########################################################\n",
    "    list_E = []\n",
    "    list_w = []\n",
    "    for i in range(len(w)):\n",
    "        if w[i] >= theta:\n",
    "            list_E.append(E[i])\n",
    "            list_w.append(w[i])\n",
    "        else:\n",
    "            m = m - 1\n",
    "    return list_E, list_w, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_acc(l):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # l: array (m x n), where m indicates the accuracies of one run of the algorithm throughout all the time units and n represents the different runs of the algorithm\n",
    "    #\n",
    "    # OUTPUT\n",
    "    # average: list in which every element reresents the mean of the accuracies of the different run at each different time\n",
    "    ########################################################\n",
    "    average = []\n",
    "    for i in range(len(l[0])):\n",
    "        suma = 0\n",
    "        for j in range(len(l)):\n",
    "            suma = suma + l[j][i]\n",
    "        average.append(suma / len(l))\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGGER Concepts\n",
    "\n",
    "First the DWM model will be evaluated with artificial datasets used to evaluate models performance with respect to concept drift. First, the STAGGER concepts are used.\n",
    "\n",
    "The STAGGER concepts constitute a way of creating a streaming dataset to evaluate the response of an algortihm to concept drift.\n",
    "\n",
    "It includes three attributes with 3 values per asttribute. The strategy is to label as True or False different combinations of attributes in sucessive time slots to evaluate the performance.\n",
    "\n",
    "* **Attributes:**\n",
    "    - ***Color:*** Green, blue and red.\n",
    "    - ***Shape:*** Triangle, circle and rectangle.\n",
    "    - ***Size:*** Small, medium and large.\n",
    "    \n",
    "The presentation of training examples lasts for 120 time steps, and at each time step, the learner receives one example. For the first 40 time steps, the target concept is color = red ∧ size = small. During the next 40 time steps, the target concept is color = green ∨ shape = circle. Finally, during the last 40 time steps, the target concept is size = medium ∨ size = large. A visualization of these concepts.\n",
    "\n",
    "To evaluate the learner, at each time step, one randomly generates 100 examples of the current target concept, presents these to the performance element, and computes the percent correctly predicted. In our experiments, we repeated this procedure 50 times and averaged the accuracies over these runs. We also computed 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"stagger.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create STAGGER concepts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stagger(number, time, max_time):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # number: Number of samples to generate within the same concept domain\n",
    "    # time: Current timestamp at which the samples are generated. It is used to define the label based on the concept domain the timestampt corresponds to.\n",
    "    # max_time: maximum timestampts in the stream. Used to calculate the boundaries for concept drift\n",
    "    # \n",
    "    # OUTPUT\n",
    "    # df: dataframe containing the specified number of samples with labels assigned matching to the current (time) concept\n",
    "    ########################################################\n",
    "    attr = {'color' : ['Red', 'Green', 'Blue'],\n",
    "            'shape' : ['Triangle', 'Circle', 'Rectangle'],\n",
    "            'size' : ['Small', 'Medium', 'Large']}\n",
    "    # Define lists\n",
    "    color_list = []\n",
    "    shape_list = []\n",
    "    size_list = []\n",
    "    label_list = []\n",
    "    # Loop to create the required data n\n",
    "    for n in range(number):\n",
    "        color_list.append(attr['color'][np.random.randint(len(attr['color']))])\n",
    "        shape_list.append(attr['shape'][np.random.randint(len(attr['shape']))])\n",
    "        size_list.append(attr['size'][np.random.randint(len(attr['size']))])\n",
    "        if(time < max_time / 3):\n",
    "            if(color_list[n] == 'Red' and size_list[n] == 'Small'):\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "        elif(max_time / 3 <= time and time < max_time * 2 / 3):\n",
    "            if(color_list[n] == 'Green' or shape_list[n] == 'Circle'):\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "        else:\n",
    "            if(size_list[n] == 'Medium' or size_list[n] == 'Large'):\n",
    "                label_list.append(1)\n",
    "            else:\n",
    "                label_list.append(0)\n",
    "    # Build dict            \n",
    "    data = {'color' : color_list,\n",
    "            'shape' : shape_list,\n",
    "            'size' : size_list,\n",
    "            'label' : label_list}\n",
    "    # Build dataframe\n",
    "    df = pd.DataFrame(data, columns = ['color', 'shape', 'size', 'label'])\n",
    "    # returns data frame\n",
    "    df = pd.get_dummies(df, prefix=['color', 'shape', 'size'], columns=['color', 'shape', 'size'])\n",
    "    \n",
    "    df = df[['color_Blue','color_Green','color_Red','shape_Circle','shape_Rectangle','shape_Triangle','size_Large','size_Medium','size_Small','label']]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_Blue</th>\n",
       "      <th>color_Green</th>\n",
       "      <th>color_Red</th>\n",
       "      <th>shape_Circle</th>\n",
       "      <th>shape_Rectangle</th>\n",
       "      <th>shape_Triangle</th>\n",
       "      <th>size_Large</th>\n",
       "      <th>size_Medium</th>\n",
       "      <th>size_Small</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    color_Blue  color_Green  color_Red  shape_Circle  shape_Rectangle  \\\n",
       "0            0            0          1             0                1   \n",
       "1            1            0          0             1                0   \n",
       "2            0            0          1             0                1   \n",
       "3            0            1          0             0                0   \n",
       "4            0            1          0             0                1   \n",
       "5            0            0          1             0                1   \n",
       "6            0            0          1             0                0   \n",
       "7            1            0          0             0                0   \n",
       "8            0            1          0             0                0   \n",
       "9            1            0          0             0                1   \n",
       "10           0            0          1             0                1   \n",
       "11           0            1          0             0                0   \n",
       "12           0            1          0             0                0   \n",
       "13           0            0          1             0                0   \n",
       "14           0            0          1             0                1   \n",
       "15           1            0          0             1                0   \n",
       "16           0            0          1             0                0   \n",
       "17           0            0          1             1                0   \n",
       "18           0            1          0             0                1   \n",
       "19           0            0          1             1                0   \n",
       "20           0            0          1             1                0   \n",
       "21           0            1          0             0                0   \n",
       "22           0            0          1             0                1   \n",
       "23           1            0          0             0                0   \n",
       "24           0            0          1             0                1   \n",
       "25           0            1          0             0                1   \n",
       "26           0            1          0             0                0   \n",
       "27           1            0          0             0                0   \n",
       "28           0            0          1             0                0   \n",
       "29           0            0          1             1                0   \n",
       "..         ...          ...        ...           ...              ...   \n",
       "70           1            0          0             1                0   \n",
       "71           1            0          0             0                1   \n",
       "72           1            0          0             1                0   \n",
       "73           1            0          0             0                1   \n",
       "74           0            0          1             0                1   \n",
       "75           1            0          0             0                1   \n",
       "76           0            1          0             0                1   \n",
       "77           0            1          0             0                1   \n",
       "78           0            1          0             1                0   \n",
       "79           0            1          0             0                0   \n",
       "80           1            0          0             0                1   \n",
       "81           1            0          0             0                1   \n",
       "82           1            0          0             1                0   \n",
       "83           1            0          0             0                1   \n",
       "84           0            1          0             1                0   \n",
       "85           0            0          1             0                1   \n",
       "86           0            0          1             0                1   \n",
       "87           0            1          0             0                0   \n",
       "88           0            1          0             1                0   \n",
       "89           1            0          0             0                0   \n",
       "90           0            0          1             0                1   \n",
       "91           0            1          0             0                1   \n",
       "92           0            0          1             1                0   \n",
       "93           0            0          1             1                0   \n",
       "94           1            0          0             0                1   \n",
       "95           0            0          1             0                0   \n",
       "96           0            0          1             1                0   \n",
       "97           0            0          1             0                1   \n",
       "98           0            0          1             0                0   \n",
       "99           0            1          0             0                1   \n",
       "\n",
       "    shape_Triangle  size_Large  size_Medium  size_Small  label  \n",
       "0                0           0            1           0      0  \n",
       "1                0           0            1           0      0  \n",
       "2                0           0            1           0      0  \n",
       "3                1           0            1           0      0  \n",
       "4                0           1            0           0      0  \n",
       "5                0           0            0           1      1  \n",
       "6                1           0            1           0      0  \n",
       "7                1           1            0           0      0  \n",
       "8                1           0            1           0      0  \n",
       "9                0           0            0           1      0  \n",
       "10               0           1            0           0      0  \n",
       "11               1           0            1           0      0  \n",
       "12               1           0            0           1      0  \n",
       "13               1           0            0           1      1  \n",
       "14               0           0            0           1      1  \n",
       "15               0           1            0           0      0  \n",
       "16               1           1            0           0      0  \n",
       "17               0           1            0           0      0  \n",
       "18               0           1            0           0      0  \n",
       "19               0           1            0           0      0  \n",
       "20               0           1            0           0      0  \n",
       "21               1           1            0           0      0  \n",
       "22               0           0            1           0      0  \n",
       "23               1           0            0           1      0  \n",
       "24               0           1            0           0      0  \n",
       "25               0           0            1           0      0  \n",
       "26               1           0            0           1      0  \n",
       "27               1           0            0           1      0  \n",
       "28               1           1            0           0      0  \n",
       "29               0           0            1           0      0  \n",
       "..             ...         ...          ...         ...    ...  \n",
       "70               0           0            0           1      0  \n",
       "71               0           0            1           0      0  \n",
       "72               0           1            0           0      0  \n",
       "73               0           1            0           0      0  \n",
       "74               0           1            0           0      0  \n",
       "75               0           0            1           0      0  \n",
       "76               0           1            0           0      0  \n",
       "77               0           0            1           0      0  \n",
       "78               0           0            0           1      0  \n",
       "79               1           0            0           1      0  \n",
       "80               0           1            0           0      0  \n",
       "81               0           1            0           0      0  \n",
       "82               0           0            0           1      0  \n",
       "83               0           1            0           0      0  \n",
       "84               0           0            0           1      0  \n",
       "85               0           0            1           0      0  \n",
       "86               0           1            0           0      0  \n",
       "87               1           0            0           1      0  \n",
       "88               0           0            1           0      0  \n",
       "89               1           0            1           0      0  \n",
       "90               0           0            1           0      0  \n",
       "91               0           1            0           0      0  \n",
       "92               0           0            0           1      1  \n",
       "93               0           0            1           0      0  \n",
       "94               0           0            1           0      0  \n",
       "95               1           1            0           0      0  \n",
       "96               0           0            1           0      0  \n",
       "97               0           0            1           0      0  \n",
       "98               1           1            0           0      0  \n",
       "99               0           0            1           0      0  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gen_stagger(100, 0, 12)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of DWM for STAGGER concepts\n",
    "\n",
    "Since all the attributes of the dataset are binary we use **Bernoulli Naives Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDWM_stagger(n_eval, max_time, beta = 0.5, theta = 0.01):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # n_eval: Number of samples to evaluate per unit of time\n",
    "    # max_time: Number of units of time\n",
    "    # beta: Weight decreasing factor\n",
    "    # theta: Weight elimination threshold\n",
    "    # \n",
    "    # OUTPUT\n",
    "    # Plot of the accuracy over time\n",
    "    # PLot of number of learners over time\n",
    "    ########################################################\n",
    "    # Initialize number of classifiers to 1\n",
    "    m = 1\n",
    "    # Number of classes\n",
    "    c = 2\n",
    "    # Create first classifier and weight\n",
    "    E = []\n",
    "    E.append(MultinomialNB())\n",
    "    normal_model = MultinomialNB()\n",
    "    perfect_model = MultinomialNB()\n",
    "    # The first fit is performed with a randomly generated sample with a default label of 1\n",
    "    E[0].partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "    normal_model.partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "    perfect_model.partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "    w = []\n",
    "    w.append(1)\n",
    "    # Lists for performance evaluation\n",
    "    Y = []\n",
    "    accuracy_DWM = []\n",
    "    accuracy_normal = []\n",
    "    accuracy_perfect = []\n",
    "    elements = []\n",
    "    for i in range(max_time):\n",
    "        df = gen_stagger(n_eval, i, max_time)\n",
    "        # Generate 100 samples 1 for training 99 for testing\n",
    "        x_train = df.to_numpy()[0][0:len(df.to_numpy()[0])-1]\n",
    "        x_test = df.to_numpy()[1:100][:,0:len(df.to_numpy()[0])-1]\n",
    "        y_train = df.to_numpy()[0][len(df.to_numpy()[0])-1]\n",
    "        y_test = df.to_numpy()[1:100][:,len(df.to_numpy()[0])-1]\n",
    "        # Create the prediction array\n",
    "        local_pred = np.array(np.zeros(c))\n",
    "        \n",
    "        # Predict for every learner from DWM\n",
    "        for j in range(m):\n",
    "            y_pred = E[j].predict(np.array(x_train, ndmin = 2))\n",
    "            if(y_pred != y_train):\n",
    "                w[j] = w[j] * beta\n",
    "            local_pred[y_pred] = local_pred[y_pred] + w[j]\n",
    "        global_pred = np.argmax(local_pred)\n",
    "\n",
    "        # Online evaluation of the model. Every time the model is fit, the model is evaluated in other 99 samples\n",
    "        \n",
    "        # Evaluate DWM\n",
    "        local_pred_test = np.zeros((x_test.shape[0], c))\n",
    "        for j in range(m):\n",
    "            y_pred_DWM = E[j].predict(x_test)\n",
    "            for k in range(local_pred_test.shape[0]):\n",
    "                local_pred_test[k][y_pred_DWM[k]] = local_pred_test[k][y_pred_DWM[k]] + w[j]\n",
    "        global_pred_test = np.argmax(local_pred_test, axis=1)\n",
    "        accuracy_DWM.append(accuracy_score(y_test, global_pred_test))\n",
    "        \n",
    "        # Evaluate Normal\n",
    "        y_pred_normal = normal_model.predict(x_test)\n",
    "        accuracy_normal.append(accuracy_score(y_test, y_pred_normal))\n",
    "        \n",
    "        # Evaluate Perfect\n",
    "        y_pred_perfect = perfect_model.predict(x_test)\n",
    "        accuracy_perfect.append(accuracy_score(y_test, y_pred_perfect))\n",
    "        \n",
    "        # Reset perfect classifier when a concept drift takes place\n",
    "        if( i == (max_time / 3) - 1 or i == (2 * max_time / 3) -1):\n",
    "            perfect_model = MultinomialNB()\n",
    "        \n",
    "        # Normalize weights and if the case eliminate elements of DWM\n",
    "        w = norm_weights(w)\n",
    "        elements.append(m)\n",
    "        E, w, m = remove_experts(E, w, theta, m)\n",
    "        if(global_pred != y_train):\n",
    "            m = m + 1\n",
    "            E.append(MultinomialNB())\n",
    "            w.append(1)\n",
    "        \n",
    "        # Partial fit of DWM \n",
    "        for j in range(m):\n",
    "            E[j].partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        Y.append(global_pred)\n",
    "        \n",
    "        # Partial fit of normal model\n",
    "        normal_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        \n",
    "        # Partial fit of perfect model\n",
    "        perfect_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "    \n",
    "    plt.figure(figsize=(8,10))\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    line1, = plt.plot(accuracy_DWM, label = 'DWM-NB')\n",
    "    line2, = plt.plot(accuracy_normal, label = 'NB', ls = '--')\n",
    "    line3, = plt.plot(accuracy_perfect, label = 'NB Perfect Forgetting', ls = '--')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('time')\n",
    "    plt.legend(handles = [line1, line2, line3])\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(elements)\n",
    "    plt.ylabel('Learners')\n",
    "    plt.xlabel('time')\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similar to the previous one but to execute the algorithm 10 times. The mean of the accuracy and of the number of learners on the 10 iterations is then plotted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDWM_stagger_mean(n_eval, max_time, beta = 0.5, theta = 0.01, loops = 10):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # n_eval: Number of samples minus one(the first sample is used to train) to evaluate per unit of time\n",
    "    # max_time: Number of units of time\n",
    "    # beta: Weight decreasing factor\n",
    "    # theta: Weight elimination threshold\n",
    "    # loops: number of runs of the algorithm\n",
    "    # \n",
    "    # OUTPUT\n",
    "    # Plot of the accuracy over time\n",
    "    # PLot of number of learners over time\n",
    "    ########################################################\n",
    "    accuracy_DWM_mean = []\n",
    "    accuracy_normal_mean = []\n",
    "    accuracy_perfect_mean = []\n",
    "    elements_mean = []\n",
    "    for l in range(loops):\n",
    "        # Initialize number of classifiers to 1\n",
    "        m = 1\n",
    "        # Number of classes\n",
    "        c = 2\n",
    "        # Create first classifier and weight\n",
    "        E = []\n",
    "        E.append(BernoulliNB())\n",
    "        normal_model = BernoulliNB()\n",
    "        perfect_model = BernoulliNB()\n",
    "        # The first fit is performed with a randomly generated sample with a default label of 1\n",
    "        E[0].partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "        normal_model.partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "        perfect_model.partial_fit(np.random.randint(2, size = (1,9)), np.array([1]), classes = [0,1])\n",
    "        w = []\n",
    "        w.append(1)\n",
    "        # Lists for performance evaluation\n",
    "        Y = []\n",
    "        accuracy_DWM = []\n",
    "        accuracy_normal = []\n",
    "        accuracy_perfect = []\n",
    "        elements = []\n",
    "        for i in range(max_time):\n",
    "            df = gen_stagger(n_eval, i, max_time)\n",
    "            # Generate 100 samples 1 for training 99 for testing\n",
    "            x_train = df.to_numpy()[0][0:len(df.to_numpy()[0])-1]\n",
    "            x_test = df.to_numpy()[1:100][:,0:len(df.to_numpy()[0])-1]\n",
    "            y_train = df.to_numpy()[0][len(df.to_numpy()[0])-1]\n",
    "            y_test = df.to_numpy()[1:100][:,len(df.to_numpy()[0])-1]\n",
    "            # Create the prediction array\n",
    "            local_pred = np.array(np.zeros(c))\n",
    "\n",
    "            # Predict for every learner from DWM\n",
    "            for j in range(m):\n",
    "                y_pred = E[j].predict(np.array(x_train, ndmin = 2))\n",
    "                if(y_pred != y_train):\n",
    "                    w[j] = w[j] * beta\n",
    "                local_pred[y_pred] = local_pred[y_pred] + w[j]\n",
    "            global_pred = np.argmax(local_pred)\n",
    "\n",
    "            # Online evaluation of the model. Every time the model is fit, the model is evaluated in other 99 samples\n",
    "\n",
    "            # Evaluate DWM\n",
    "            local_pred_test = np.zeros((x_test.shape[0], c))\n",
    "            for j in range(m):\n",
    "                y_pred_DWM = E[j].predict(x_test)\n",
    "                for k in range(local_pred_test.shape[0]):\n",
    "                    local_pred_test[k][y_pred_DWM[k]] = local_pred_test[k][y_pred_DWM[k]] + w[j]\n",
    "            global_pred_test = np.argmax(local_pred_test, axis=1)\n",
    "            accuracy_DWM.append(accuracy_score(y_test, global_pred_test))\n",
    "\n",
    "            # Evaluate Normal\n",
    "            y_pred_normal = normal_model.predict(x_test)\n",
    "            accuracy_normal.append(accuracy_score(y_test, y_pred_normal))\n",
    "\n",
    "            # Evaluate Perfect\n",
    "            y_pred_perfect = perfect_model.predict(x_test)\n",
    "            accuracy_perfect.append(accuracy_score(y_test, y_pred_perfect))\n",
    "\n",
    "            # Reset perfect classifier when a concept drift takes place\n",
    "            if( i == (max_time / 3) - 1 or i == (2 * max_time / 3) -1):\n",
    "                perfect_model = MultinomialNB()\n",
    "\n",
    "            # Normalize weights and if the case eliminate elements of DWM\n",
    "            w = norm_weights(w)\n",
    "            elements.append(m)\n",
    "            E, w, m = remove_experts(E, w, theta, m)\n",
    "            if(global_pred != y_train):\n",
    "                m = m + 1\n",
    "                E.append(MultinomialNB())\n",
    "                w.append(1)\n",
    "\n",
    "            # Partial fit of DWM \n",
    "            for j in range(m):\n",
    "                E[j].partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "            Y.append(global_pred)\n",
    "\n",
    "            # Partial fit of normal model\n",
    "            normal_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "\n",
    "            # Partial fit of perfect model\n",
    "            perfect_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        accuracy_DWM_mean.append(accuracy_DWM)\n",
    "        accuracy_normal_mean.append(accuracy_normal)\n",
    "        accuracy_perfect_mean.append(accuracy_perfect)\n",
    "        elements_mean.append(elements)\n",
    "    plt.figure(figsize=(8,10))\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    line1, = plt.plot(avg_acc(accuracy_DWM_mean), label = 'DWM-NB')\n",
    "    line2, = plt.plot(avg_acc(accuracy_normal_mean), label = 'NB', ls = '--')\n",
    "    line3, = plt.plot(avg_acc(accuracy_perfect_mean), label = 'NB Perfect Forgetting', ls = '--')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('time')\n",
    "    plt.legend(handles = [line1, line2, line3])\n",
    "    \n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(avg_acc(elements_mean))\n",
    "    plt.ylabel('Learners')\n",
    "    plt.xlabel('time')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateDWM_stagger(100, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDWM_sea(n_eval, max_time, beta = 0.5, theta = 0.01):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # max_time: Number of units of time\n",
    "    # beta: Weight decreasing factor\n",
    "    # theta: Weight elimination threshold\n",
    "    # \n",
    "    # OUTPUT\n",
    "    # Plot of the accuracy over time\n",
    "    # PLot of number of learners over time\n",
    "    ########################################################\n",
    "    # Initialize number of classifiers to 1\n",
    "    m = 1\n",
    "    # Number of classes\n",
    "    c = 2\n",
    "    # Create first classifier and weight\n",
    "    E = []\n",
    "    E.append(GaussianNB())\n",
    "    normal_model = GaussianNB()\n",
    "    perfect_model = GaussianNB()\n",
    "    # The first fit is performed with a randomly generated sample with a default label of 1\n",
    "    E[0].partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "    normal_model.partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "    perfect_model.partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "    w = []\n",
    "    w.append(1)\n",
    "    # Lists for performance evaluation\n",
    "    Y = []\n",
    "    accuracy_DWM = []\n",
    "    accuracy_normal = []\n",
    "    accuracy_perfect = []\n",
    "    elements = []\n",
    "    for i in range(max_time):\n",
    "        df = gen_sea(n_eval, i, max_time)\n",
    "        # Generate 100 samples 1 for training 99 for testing\n",
    "        x_train = df.to_numpy()[0][0:len(df.to_numpy()[0] ) - 1]\n",
    "        x_test = df.to_numpy()[1:100][:,0:len(df.to_numpy()[0]) - 1]\n",
    "        y_train = int(df.to_numpy()[0][len(df.to_numpy()[0]) - 1])\n",
    "        y_test = np.array(df.to_numpy()[1:100][:,len(df.to_numpy()[0]) - 1], dtype = int)\n",
    "        # Create the prediction array\n",
    "        local_pred = np.array(np.zeros(c))\n",
    "        \n",
    "        # Predict for every learner from DWM\n",
    "        for j in range(m):\n",
    "            y_pred = E[j].predict(np.array(x_train, ndmin = 2))\n",
    "            if(y_pred != y_train):\n",
    "                w[j] = w[j] * beta\n",
    "            local_pred[y_pred] = local_pred[y_pred] + w[j]\n",
    "        global_pred = np.argmax(local_pred)\n",
    "        # Online evaluation of the model. Every time the model is fit, the model is evaluated in other 99 samples\n",
    "        \n",
    "        # Evaluate DWM\n",
    "        local_pred_test = np.zeros((x_test.shape[0], c))\n",
    "        for j in range(m):\n",
    "            y_pred_DWM = E[j].predict(x_test)\n",
    "            for k in range(local_pred_test.shape[0]):\n",
    "                local_pred_test[k][y_pred_DWM[k]] = local_pred_test[k][y_pred_DWM[k]] + w[j]\n",
    "        global_pred_test = np.argmax(local_pred_test, axis=1)\n",
    "        accuracy_DWM.append(accuracy_score(y_test, global_pred_test))\n",
    "        \n",
    "        # Evaluate Normal\n",
    "        y_pred_normal = normal_model.predict(x_test)\n",
    "        accuracy_normal.append(accuracy_score(y_test, y_pred_normal))\n",
    "        \n",
    "        # Evaluate Perfect\n",
    "        y_pred_perfect = perfect_model.predict(x_test)\n",
    "        accuracy_perfect.append(accuracy_score(y_test, y_pred_perfect))\n",
    "        \n",
    "        # Reset perfect classifier when a concept drift takes place\n",
    "        if( i == (max_time / 4) - 1 or i == (max_time / 2) or i == (3 * max_time / 4) -1):\n",
    "            perfect_model = GaussianNB()\n",
    "        \n",
    "        # Normalize weights and if the case eliminate elements of DWM\n",
    "        w = norm_weights(w)\n",
    "        elements.append(m)\n",
    "        E, w, m = remove_experts(E, w, theta, m)\n",
    "        if(global_pred != y_train):\n",
    "            m = m + 1\n",
    "            E.append(GaussianNB())\n",
    "            w.append(1)\n",
    "        \n",
    "        # Partial fit of DWM \n",
    "        for j in range(m):\n",
    "            E[j].partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        Y.append(global_pred)\n",
    "        \n",
    "        # Partial fit of normal model\n",
    "        normal_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        # Partial fit of perfect model\n",
    "        perfect_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.7,1])\n",
    "    axes.set_xlim([0,max_time])\n",
    "    line1, = plt.plot(accuracy_DWM, label = 'DWM-NB')\n",
    "    line2, = plt.plot(accuracy_normal, label = 'NB', ls = '--')\n",
    "    line3, = plt.plot(accuracy_perfect, label = 'NB Perfect Forgetting', ls = '--')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('time')\n",
    "    plt.legend(handles = [line1, line2, line3])\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(elements)\n",
    "    plt.ylabel('Learners')\n",
    "    plt.xlabel('time')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDWM_sea_mean(n_eval, max_time, beta = 0.5, theta = 0.01, loops = 10):\n",
    "    #######################################################\n",
    "    # INPUT\n",
    "    # max_time: Number of units of time\n",
    "    # beta: Weight decreasing factor\n",
    "    # theta: Weight elimination threshold\n",
    "    # \n",
    "    # OUTPUT\n",
    "    # Plot of the accuracy over time\n",
    "    # PLot of number of learners over time\n",
    "    ########################################################\n",
    "    accuracy_DWM_mean = []\n",
    "    accuracy_normal_mean = []\n",
    "    accuracy_perfect_mean = []\n",
    "    elements_mean = []\n",
    "    for l in range(loops):\n",
    "        print(l)\n",
    "        # Initialize number of classifiers to 1\n",
    "        m = 1\n",
    "        # Number of classes\n",
    "        c = 2\n",
    "        # Create first classifier and weight\n",
    "        E = []\n",
    "        E.append(GaussianNB())\n",
    "        normal_model = GaussianNB()\n",
    "        perfect_model = GaussianNB()\n",
    "        # The first fit is performed with a randomly generated sample with a default label of 1\n",
    "        E[0].partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "        normal_model.partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "        perfect_model.partial_fit(np.random.uniform(0,10, size = (1,3)), np.array([1]), classes = [0,1])\n",
    "        w = []\n",
    "        w.append(1)\n",
    "        # Lists for performance evaluation\n",
    "        Y = []\n",
    "        accuracy_DWM = []\n",
    "        accuracy_normal = []\n",
    "        accuracy_perfect = []\n",
    "        elements = []\n",
    "        for i in range(max_time):\n",
    "            df = gen_sea(n_eval, i, max_time)\n",
    "            # Generate 100 samples 1 for training 99 for testing\n",
    "            x_train = df.to_numpy()[0][0:len(df.to_numpy()[0] ) - 1]\n",
    "            x_test = df.to_numpy()[1:100][:,0:len(df.to_numpy()[0]) - 1]\n",
    "            y_train = int(df.to_numpy()[0][len(df.to_numpy()[0]) - 1])\n",
    "            y_test = np.array(df.to_numpy()[1:100][:,len(df.to_numpy()[0]) - 1], dtype = int)\n",
    "            # Create the predicion array\n",
    "            local_pred = np.array(np.zeros(c))\n",
    "\n",
    "            # Predict for every learner from DWM\n",
    "            for j in range(m):\n",
    "                y_pred = E[j].predict(np.array(x_train, ndmin = 2))\n",
    "                if(y_pred != y_train):\n",
    "                    w[j] = w[j] * beta\n",
    "                local_pred[y_pred] = local_pred[y_pred] + w[j]\n",
    "            global_pred = np.argmax(local_pred)\n",
    "            # Online evaluation of the model. Every time the model is fit, the model is evaluated in other 99 samples\n",
    "\n",
    "            # Evaluate DWM\n",
    "            local_pred_test = np.zeros((x_test.shape[0], c))\n",
    "            for j in range(m):\n",
    "                y_pred_DWM = E[j].predict(x_test)\n",
    "                for k in range(local_pred_test.shape[0]):\n",
    "                    local_pred_test[k][y_pred_DWM[k]] = local_pred_test[k][y_pred_DWM[k]] + w[j]\n",
    "            global_pred_test = np.argmax(local_pred_test, axis=1)\n",
    "            accuracy_DWM.append(accuracy_score(y_test, global_pred_test))\n",
    "\n",
    "            # Evaluate Normal\n",
    "            y_pred_normal = normal_model.predict(x_test)\n",
    "            accuracy_normal.append(accuracy_score(y_test, y_pred_normal))\n",
    "\n",
    "            # Evaluate Perfect\n",
    "            y_pred_perfect = perfect_model.predict(x_test)\n",
    "            accuracy_perfect.append(accuracy_score(y_test, y_pred_perfect))\n",
    "\n",
    "            # Reset perfect classifier when a concept drift takes place\n",
    "            if( i == (max_time / 4) - 1 or i == (max_time / 2) or i == (3 * max_time / 4) -1):\n",
    "                perfect_model = GaussianNB()\n",
    "\n",
    "            # Normalize weights and if the case eliminate elements of DWM\n",
    "            w = norm_weights(w)\n",
    "            elements.append(m)\n",
    "            E, w, m = remove_experts(E, w, theta, m)\n",
    "            if(global_pred != y_train):\n",
    "                m = m + 1\n",
    "                E.append(GaussianNB())\n",
    "                w.append(1)\n",
    "\n",
    "            # Partial fit of DWM \n",
    "            for j in range(m):\n",
    "                E[j].partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "            Y.append(global_pred)\n",
    "            # Partial fit of normal model\n",
    "            normal_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "            # Partial fit of perfect model\n",
    "            perfect_model.partial_fit(np.array(x_train, ndmin = 2), np.array(y_train, ndmin = 2), classes = [0,1])\n",
    "        \n",
    "        accuracy_DWM_mean.append(accuracy_DWM)\n",
    "        accuracy_normal_mean.append(accuracy_normal)\n",
    "        accuracy_perfect_mean.append(accuracy_perfect)\n",
    "        elements_mean.append(elements)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.7,1])\n",
    "    axes.set_xlim([0,max_time])\n",
    "    plt.subplot(2,1,1)\n",
    "    line1, = plt.plot(avg_acc(accuracy_DWM_mean), label = 'DWM-NB')\n",
    "    line2, = plt.plot(avg_acc(accuracy_normal_mean), label = 'NB', ls = '--')\n",
    "    line3, = plt.plot(avg_acc(accuracy_perfect_mean), label = 'NB Perfect Forgetting', ls = '--')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('time')\n",
    "    plt.legend(handles = [line1, line2, line3])\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(elements)\n",
    "    plt.ylabel('Learners')\n",
    "    plt.xlabel('time')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate DWM for SEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
